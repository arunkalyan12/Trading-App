{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "284caaab-ec4b-4d28-856f-aad0e5c53831",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T17:31:20.659953Z",
     "iopub.status.busy": "2025-12-07T17:31:20.659488Z",
     "iopub.status.idle": "2025-12-07T17:31:20.675663Z",
     "shell.execute_reply": "2025-12-07T17:31:20.673742Z",
     "shell.execute_reply.started": "2025-12-07T17:31:20.659915Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Clean the data by replacing infinities with NaN and dropping rows with NaN.\"\"\"\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_labels(df: pd.DataFrame, horizon=5, atr_mult=1.5, threshold = 0.2) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df['future_close'] = df['Close'].shift(-horizon)\n",
    "    df['future_ret'] = (df['future_close'] - df['Close']) / df['Close']\n",
    "\n",
    "    # Consensus of indicators\n",
    "    consensus = (\n",
    "        0.25 * np.sign(df.get('ema_diff_9_21', 0)) +\n",
    "        0.20 * np.sign(df.get('macd_hist', 0)) +\n",
    "        0.15 * np.sign(df.get('rsi_norm', 0)) +\n",
    "        0.15 * df.get('supertrend_dir', 0) +\n",
    "        0.10 * np.sign(df.get('cci_norm', 0)) +\n",
    "        0.10 * np.sign(df.get('obv_slope', 0)) +\n",
    "        0.05 * np.sign(df.get('mfi_norm', 0))\n",
    "    )\n",
    "    df['consensus_score'] = consensus.clip(-1,1)\n",
    "\n",
    "    atr_threshold = df['atr_pct'].rolling(20).mean() * atr_mult\n",
    "    df['label_prob'] = np.tanh(df['future_ret'] / (atr_threshold + 1e-6)) * df['consensus_score']\n",
    "\n",
    "    buy_cond = df['label_prob'] > threshold\n",
    "    sell_cond = df['label_prob'] < -threshold\n",
    "    df['label'] = 0\n",
    "    df.loc[buy_cond, 'label'] = 1\n",
    "    df.loc[sell_cond, 'label'] = -1\n",
    "\n",
    "    df.dropna(subset=['label_prob'], inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    df: pandas DataFrame with columns ['open','high','low','close','volume']\n",
    "    Returns: df with features for Core 12 indicators ready for ML/backtesting\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    df['Close'] = pd.to_numeric(df['Close'], errors='coerce')\n",
    "    df['Open'] = pd.to_numeric(df['Open'], errors='coerce')\n",
    "    df['High'] = pd.to_numeric(df['High'], errors='coerce')\n",
    "    df['Low'] = pd.to_numeric(df['Low'], errors='coerce')\n",
    "    df['Volume'] = pd.to_numeric(df['Volume'], errors='coerce')\n",
    "\n",
    "    df = clean_data(df)\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "    #Load the dataset\n",
    "    # df = pd.read_csv(file_path)\n",
    "    \n",
    "    #Clean Data\n",
    "    df = clean_data(df)\n",
    "\n",
    "    #Convert ''Open Time' and 'Close Time' to datetime\n",
    "    df['Open Time'] = pd.to_datetime(df['Open Time'], unit='ms')\n",
    "    df['Close Time'] = pd.to_datetime(df['Close Time'], unit='ms')\n",
    "\n",
    "    # Set the 'Open Time' as the index\n",
    "    df.set_index('Open Time', inplace=True)\n",
    "\n",
    "    # Feature engineering and label generation\n",
    "    df = feature_engineering(df)\n",
    "\n",
    "    # Replace infinite values with NaN\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    # Drop rows with NaN values generated during calculations\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a86cb4-b6aa-4598-af0e-16b47ffea182",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T17:20:42.913492Z",
     "iopub.status.busy": "2025-12-07T17:20:42.912965Z",
     "iopub.status.idle": "2025-12-07T17:20:45.534213Z",
     "shell.execute_reply": "2025-12-07T17:20:45.532946Z",
     "shell.execute_reply.started": "2025-12-07T17:20:42.913460Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-07 17:20:43.261497: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.metrics import MeanSquaredError, MeanAbsoluteError\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "79e1f46e-a579-4bc0-bbed-91757e877c07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T19:58:13.263269Z",
     "iopub.status.busy": "2025-12-07T19:58:13.262909Z",
     "iopub.status.idle": "2025-12-07T19:58:13.273167Z",
     "shell.execute_reply": "2025-12-07T19:58:13.271637Z",
     "shell.execute_reply.started": "2025-12-07T19:58:13.263240Z"
    }
   },
   "outputs": [],
   "source": [
    "from config_loader import load_config\n",
    "config = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6298f85b-aef0-473f-adf1-ce567702dbff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T19:58:18.648894Z",
     "iopub.status.busy": "2025-12-07T19:58:18.648583Z",
     "iopub.status.idle": "2025-12-07T19:58:18.655451Z",
     "shell.execute_reply": "2025-12-07T19:58:18.654383Z",
     "shell.execute_reply.started": "2025-12-07T19:58:18.648868Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the Attention layer\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class Attention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(\n",
    "            name='attention_weight',\n",
    "            shape=(input_shape[-1], 1),\n",
    "            initializer='random_normal',\n",
    "            trainable=True\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            name='attention_bias',\n",
    "            shape=(input_shape[1], 1),\n",
    "            initializer='zeros',\n",
    "            trainable=True\n",
    "        )\n",
    "        super(Attention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = K.tanh(K.dot(x, self.W) + self.b)\n",
    "        e = K.squeeze(e, axis=-1)\n",
    "        alpha = K.softmax(e)\n",
    "        alpha = K.expand_dims(alpha, axis=-1)\n",
    "        context = x * alpha\n",
    "        context = K.sum(context, axis=1)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "961bb492-724e-4d6f-94d8-c67e523ab50c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T17:35:08.088551Z",
     "iopub.status.busy": "2025-12-07T17:35:08.088047Z",
     "iopub.status.idle": "2025-12-07T17:35:08.952607Z",
     "shell.execute_reply": "2025-12-07T17:35:08.951416Z",
     "shell.execute_reply.started": "2025-12-07T17:35:08.088514Z"
    }
   },
   "outputs": [],
   "source": [
    "symbol = config['data']['symbol']\n",
    "interval = config['data']['interval']\n",
    "start_time = int(pd.Timestamp(config['backtesting']['start_date']).timestamp() * 1000)\n",
    "end_time = int(pd.Timestamp(config['backtesting']['end_date']).timestamp() * 1000)\n",
    "\n",
    "# df = ingest_data(symbol, interval, start_time, end_time,r'C:/Users/arunm/Documents/Projects/Trading-App/Data/Raw/Pipeline_raw.csv')\n",
    "\n",
    "df = pd.read_csv(r'Pipeline_raw.csv')\n",
    "# logger.info(\"Data ingestion completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f059f48-4d24-47c6-9423-8f460d56824d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T17:35:09.085755Z",
     "iopub.status.busy": "2025-12-07T17:35:09.085393Z",
     "iopub.status.idle": "2025-12-07T17:35:09.341040Z",
     "shell.execute_reply": "2025-12-07T17:35:09.339942Z",
     "shell.execute_reply.started": "2025-12-07T17:35:09.085725Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocessed_df = preprocess_data(df)\n",
    "preprocessed_df.dropna(inplace=True)\n",
    "# logger.info(\"Data preprocessing completed successfully.\")\n",
    "\n",
    "feature_scaler = MinMaxScaler()\n",
    "target_scaler = MinMaxScaler()\n",
    "\n",
    "# Scale features once here\n",
    "preprocessed_df[['Open', 'High', 'Low', 'Volume']] = feature_scaler.fit_transform(\n",
    "    preprocessed_df[['Open', 'High', 'Low', 'Volume']]\n",
    ")\n",
    "preprocessed_df['Close'] = target_scaler.fit_transform(preprocessed_df[['Close']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bb68578-0ed1-46f4-9105-b469a354c92d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T17:35:20.827285Z",
     "iopub.status.busy": "2025-12-07T17:35:20.826822Z",
     "iopub.status.idle": "2025-12-07T17:35:20.963420Z",
     "shell.execute_reply": "2025-12-07T17:35:20.960857Z",
     "shell.execute_reply.started": "2025-12-07T17:35:20.827255Z"
    }
   },
   "outputs": [],
   "source": [
    "custom_objects = {\n",
    "    \"Custom>Attention\": Attention,\n",
    "    \"Attention\": Attention,\n",
    "    \"mse\": MeanSquaredError(),\n",
    "    \"mae\": MeanAbsoluteError(),\n",
    "}\n",
    "\n",
    "model_path = r\"gru_model.h5\"\n",
    "model = load_model(model_path, custom_objects=custom_objects, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de001c5b-1fa5-4560-b0cb-c47a996671d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T17:35:23.036253Z",
     "iopub.status.busy": "2025-12-07T17:35:23.035896Z",
     "iopub.status.idle": "2025-12-07T17:36:29.192383Z",
     "shell.execute_reply": "2025-12-07T17:36:29.191193Z",
     "shell.execute_reply.started": "2025-12-07T17:35:23.036223Z"
    }
   },
   "outputs": [],
   "source": [
    "features = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "X_test = preprocessed_df[features].copy()   # <<< already scaled; no second scaler\n",
    "\n",
    "SEQ_LENGTH = 60\n",
    "FORECAST_LENGTH = 25\n",
    "\n",
    "def create_sequences(df, seq_length, forecast_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(df) - seq_length - forecast_length):\n",
    "        seq = df.iloc[i:i + seq_length].values\n",
    "        tgt = df['Close'].iloc[i + seq_length:i + seq_length + forecast_length]\n",
    "        X.append(seq)\n",
    "        y.append(tgt)\n",
    "    return X, y\n",
    "\n",
    "X, y = create_sequences(X_test, SEQ_LENGTH, FORECAST_LENGTH)\n",
    "X = np.array(X, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b2a0adb-0d13-4f67-90f3-d427a3bbea74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T17:36:29.197951Z",
     "iopub.status.busy": "2025-12-07T17:36:29.197621Z",
     "iopub.status.idle": "2025-12-07T17:44:29.113282Z",
     "shell.execute_reply": "2025-12-07T17:44:29.112383Z",
     "shell.execute_reply.started": "2025-12-07T17:36:29.197919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19919/19919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m472s\u001b[0m 24ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "540487f5-2039-450b-b210-a0777c8fed94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T19:21:14.957495Z",
     "iopub.status.busy": "2025-12-07T19:21:14.957020Z",
     "iopub.status.idle": "2025-12-07T19:21:14.986222Z",
     "shell.execute_reply": "2025-12-07T19:21:14.984638Z",
     "shell.execute_reply.started": "2025-12-07T19:21:14.957457Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def backtest_regression_simple_centered_v4(\n",
    "    df: pd.DataFrame,\n",
    "    y_pred: np.ndarray,\n",
    "    config,\n",
    "    horizon: int = 50,\n",
    "    quantile: float = 0.90,\n",
    "    max_hold: int = None,\n",
    "    invert_signal: bool = True,\n",
    "    side_mode: str = \"both\",   # \"both\", \"long_only\", \"short_only\"\n",
    "    max_loss_cap: float = -3.5,\n",
    "    decay_factor: float = 0.5,  # exit when |pred_now| < decay_factor * |pred_at_entry|\n",
    "):\n",
    "    \"\"\"\n",
    "    Simple but enhanced regression backtester:\n",
    "\n",
    "      - Centered predicted returns\n",
    "      - Quantile threshold -> signals\n",
    "      - Optional inversion (model anti-directional)\n",
    "      - Optional side filter: both / long_only / short_only\n",
    "      - Fixed-horizon exit + predictive exits:\n",
    "          * HARD_STOP (pnl <= max_loss_cap)\n",
    "          * MODEL_FLIP (pred sign flips vs entry)\n",
    "          * DECAY (pred magnitude collapses vs entry)\n",
    "          * TIME (max_hold reached)\n",
    "      - Diagnostics for analysis\n",
    "\n",
    "    All trades are implemented as long-only in PnL math (position > 0),\n",
    "    but side_mode controls which signal directions are allowed to enter.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1. Align predictions\n",
    "    # -----------------------------\n",
    "    if y_pred.ndim > 1:\n",
    "        # Average first `horizon` steps if shape is (N, H)\n",
    "        future_pred = np.mean(y_pred[:, :horizon], axis=1)\n",
    "    else:\n",
    "        future_pred = y_pred\n",
    "\n",
    "    # Align df to prediction length\n",
    "    df = df.iloc[-len(future_pred):].copy()\n",
    "    df[\"future_pred\"] = future_pred\n",
    "\n",
    "    # -----------------------------\n",
    "    # 2. Predicted return (raw)\n",
    "    # -----------------------------\n",
    "    df[\"pred_ret_raw\"] = (df[\"future_pred\"] - df[\"Close\"]) / df[\"Close\"]\n",
    "\n",
    "    # Model seems anti-directional → invert by default\n",
    "    if invert_signal:\n",
    "        df[\"pred_ret_raw\"] = -df[\"pred_ret_raw\"]\n",
    "\n",
    "    # -----------------------------\n",
    "    # 3. Centering (CRITICAL)\n",
    "    # -----------------------------\n",
    "    center_lb = 200  # rolling median window\n",
    "    df[\"center\"] = df[\"pred_ret_raw\"].rolling(center_lb).median().fillna(0.0)\n",
    "    df[\"pred_ret\"] = df[\"pred_ret_raw\"] - df[\"center\"]\n",
    "\n",
    "    # -----------------------------\n",
    "    # 4. Quantile threshold on centered predictions\n",
    "    # -----------------------------\n",
    "    thr = df[\"pred_ret\"].abs().quantile(quantile)\n",
    "    if (not np.isfinite(thr)) or thr == 0:\n",
    "        thr = df[\"pred_ret\"].abs().mean()  # fallback\n",
    "\n",
    "    df[\"signal\"] = 0\n",
    "    df.loc[df[\"pred_ret\"] > thr, \"signal\"] = 1\n",
    "    df.loc[df[\"pred_ret\"] < -thr, \"signal\"] = -1\n",
    "\n",
    "    # Only enter when signal changes (avoid spam)\n",
    "    df[\"entry\"] = (df[\"signal\"] != 0) & df[\"signal\"].ne(df[\"signal\"].shift(1))\n",
    "\n",
    "    # -----------------------------\n",
    "    # 5. Backtest core\n",
    "    # -----------------------------\n",
    "    if max_hold is None:\n",
    "        max_hold = horizon\n",
    "\n",
    "    initial_balance = config[\"backtesting\"][\"initial_balance\"]\n",
    "    risk_pct = config[\"risk_management\"][\"risk_percentage\"]\n",
    "\n",
    "    balance = initial_balance\n",
    "    position = 0.0\n",
    "    entry_price = 0.0\n",
    "    hold = 0\n",
    "\n",
    "    entry_signal = None\n",
    "    entry_pred = None\n",
    "\n",
    "    trades: list[dict] = []\n",
    "    equity_curve: list[float] = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        price = float(row[\"Close\"])\n",
    "        pred_now = float(row[\"pred_ret\"])\n",
    "        equity_curve.append(balance + position * price)\n",
    "\n",
    "        # --------------------------------\n",
    "        # Decide if this signal side is allowed\n",
    "        # --------------------------------\n",
    "        side_ok = True\n",
    "        if side_mode == \"long_only\":\n",
    "            side_ok = (row[\"signal\"] == 1)\n",
    "        elif side_mode == \"short_only\":\n",
    "            side_ok = (row[\"signal\"] == -1)\n",
    "\n",
    "        # --------------------------------\n",
    "        # ENTRY\n",
    "        # --------------------------------\n",
    "        if position == 0 and row[\"entry\"] and side_ok:\n",
    "            size = balance * (risk_pct / 100.0)\n",
    "            if size <= 0:\n",
    "                continue\n",
    "\n",
    "            position = size / price\n",
    "            balance -= size\n",
    "            entry_price = price\n",
    "            hold = 0\n",
    "            entry_signal = row[\"signal\"]\n",
    "            entry_pred = pred_now\n",
    "\n",
    "            trades.append({\n",
    "                \"type\": \"ENTRY\",\n",
    "                \"signal\": entry_signal,\n",
    "                \"price\": price,\n",
    "                \"index\": i,\n",
    "                \"pred_ret_entry\": entry_pred,\n",
    "            })\n",
    "\n",
    "        # --------------------------------\n",
    "        # EXIT logic\n",
    "        # --------------------------------\n",
    "        elif position > 0:\n",
    "            hold += 1\n",
    "            pnl = (price - entry_price) * position\n",
    "            exit_reason = None\n",
    "\n",
    "            # 1) HARD_STOP\n",
    "            if pnl <= max_loss_cap:\n",
    "                exit_reason = \"HARD_STOP\"\n",
    "\n",
    "            # 2) MODEL_FLIP (prediction sign flips vs entry)\n",
    "            elif entry_pred is not None and entry_signal is not None:\n",
    "                if np.sign(pred_now) * np.sign(entry_pred) < 0:\n",
    "                    exit_reason = \"MODEL_FLIP\"\n",
    "\n",
    "            # 3) DECAY (prediction magnitude has collapsed vs entry)\n",
    "            if exit_reason is None and entry_pred is not None:\n",
    "                if abs(pred_now) < decay_factor * abs(entry_pred):\n",
    "                    exit_reason = \"DECAY\"\n",
    "\n",
    "            # 4) TIME EXIT\n",
    "            if exit_reason is None and hold >= max_hold:\n",
    "                exit_reason = \"TIME\"\n",
    "\n",
    "            if exit_reason is not None:\n",
    "                balance += position * price\n",
    "                trades.append({\n",
    "                    \"type\": \"EXIT\",\n",
    "                    \"price\": price,\n",
    "                    \"index\": i,\n",
    "                    \"pnl\": pnl,\n",
    "                    \"hold\": hold,\n",
    "                    \"reason\": exit_reason,\n",
    "                })\n",
    "                position = 0.0\n",
    "                entry_signal = None\n",
    "                entry_pred = None\n",
    "\n",
    "    # -----------------------------\n",
    "    # 6. Final liquidation if needed\n",
    "    # -----------------------------\n",
    "    if position > 0:\n",
    "        balance += position * df[\"Close\"].iloc[-1]\n",
    "        position = 0.0\n",
    "\n",
    "    final_balance = balance\n",
    "    profit_pct = 100.0 * (final_balance - initial_balance) / initial_balance\n",
    "\n",
    "    trades_df = pd.DataFrame(trades)\n",
    "    trades_df[\"pnl\"] = trades_df.get(\"pnl\", np.nan)\n",
    "\n",
    "    if len(equity_curve) > 0:\n",
    "        equity = pd.Series(equity_curve, index=df.index[:len(equity_curve)])\n",
    "        max_dd = (equity / equity.cummax() - 1).min()\n",
    "    else:\n",
    "        equity = pd.Series(dtype=float)\n",
    "        max_dd = 0.0\n",
    "\n",
    "    # -----------------------------\n",
    "    # 7. Diagnostics\n",
    "    # -----------------------------\n",
    "    diagnostics = {}\n",
    "\n",
    "    diagnostics[\"pred_ret_raw_stats\"] = df[\"pred_ret_raw\"].describe()\n",
    "    diagnostics[\"pred_ret_centered_stats\"] = df[\"pred_ret\"].describe()\n",
    "    diagnostics[\"signal_counts\"] = df[\"signal\"].value_counts(dropna=False)\n",
    "    diagnostics[\"threshold_value\"] = thr\n",
    "    diagnostics[\"center_median\"] = df[\"center\"].median()\n",
    "    diagnostics[\"entry_rate_pct\"] = 100.0 * df[\"entry\"].sum() / len(df)\n",
    "    diagnostics[\"trade_count\"] = len(trades_df)\n",
    "    diagnostics[\"win_rate\"] = (trades_df[\"pnl\"] > 0).mean() if len(trades_df) else np.nan\n",
    "    diagnostics[\"avg_pnl\"] = trades_df[\"pnl\"].mean() if len(trades_df) else np.nan\n",
    "    diagnostics[\"max_loss_cap\"] = max_loss_cap\n",
    "    diagnostics[\"decay_factor\"] = decay_factor\n",
    "    diagnostics[\"side_mode\"] = side_mode\n",
    "\n",
    "    if \"hold\" in trades_df:\n",
    "        diagnostics[\"hold_distribution\"] = trades_df[\"hold\"].describe()\n",
    "\n",
    "    if \"reason\" in trades_df:\n",
    "        diagnostics[\"exit_reason_counts\"] = trades_df[\"reason\"].value_counts(dropna=False)\n",
    "\n",
    "    if \"pnl\" in trades_df and len(trades_df) > 0:\n",
    "        diagnostics[\"top_5_winners\"] = trades_df.nlargest(5, \"pnl\")\n",
    "        diagnostics[\"top_5_losers\"] = trades_df.nsmallest(5, \"pnl\")\n",
    "\n",
    "        joined = trades_df.join(df[\"pred_ret\"], on=\"index\", rsuffix=\"_pred\")\n",
    "        diagnostics[\"pred_ret_pnl_corr\"] = joined[[\"pred_ret\", \"pnl\"]].corr().iloc[0, 1]\n",
    "    else:\n",
    "        diagnostics[\"top_5_winners\"] = pd.DataFrame()\n",
    "        diagnostics[\"top_5_losers\"] = pd.DataFrame()\n",
    "        diagnostics[\"pred_ret_pnl_corr\"] = np.nan\n",
    "\n",
    "    return {\n",
    "        \"final_balance\": final_balance,\n",
    "        \"profit_pct\": profit_pct,\n",
    "        \"trades\": trades_df,\n",
    "        \"equity_curve\": equity,\n",
    "        \"max_drawdown\": max_dd,\n",
    "        \"diagnostics\": diagnostics,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "005e221e-5f55-444d-83a6-691743b11080",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T18:15:12.473127Z",
     "iopub.status.busy": "2025-12-07T18:15:12.472764Z",
     "iopub.status.idle": "2025-12-07T18:15:12.516526Z",
     "shell.execute_reply": "2025-12-07T18:15:12.514685Z",
     "shell.execute_reply.started": "2025-12-07T18:15:12.473095Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_flat = y_pred.reshape(-1, 1)\n",
    "y_pred_unscaled_flat = target_scaler.inverse_transform(y_pred_flat)\n",
    "y_pred_unscaled = y_pred_unscaled_flat.reshape(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b5202817-d482-4db5-bf24-fd1880e1a048",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T19:58:24.780935Z",
     "iopub.status.busy": "2025-12-07T19:58:24.780443Z",
     "iopub.status.idle": "2025-12-07T19:58:47.841860Z",
     "shell.execute_reply": "2025-12-07T19:58:47.840784Z",
     "shell.execute_reply.started": "2025-12-07T19:58:24.780894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Backtest Results ---\n",
      "Final Balance: 10130.13\n",
      "Profit %: 1.30%\n",
      "Trades: 1156\n",
      "Win Rate: 27.85%\n",
      "Avg PnL: 0.225137\n",
      "Max DD: -0.30%\n",
      "\n",
      "=== DIAGNOSTICS ===\n",
      "\n",
      "--- pred_ret_raw_stats ---\n",
      "count    637393.000000\n",
      "mean          0.067066\n",
      "std           0.043382\n",
      "min          -0.084849\n",
      "25%           0.027922\n",
      "50%           0.059439\n",
      "75%           0.112999\n",
      "max           0.165325\n",
      "Name: pred_ret_raw, dtype: float64\n",
      "\n",
      "--- pred_ret_centered_stats ---\n",
      "count    637393.000000\n",
      "mean         -0.000030\n",
      "std           0.004890\n",
      "min          -0.093883\n",
      "25%          -0.001774\n",
      "50%           0.000005\n",
      "75%           0.001823\n",
      "max           0.064364\n",
      "Name: pred_ret, dtype: float64\n",
      "\n",
      "--- signal_counts ---\n",
      "signal\n",
      " 0    624645\n",
      "-1      6749\n",
      " 1      5999\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- threshold_value ---\n",
      "0.014644089453639372\n",
      "\n",
      "--- center_median ---\n",
      "0.058381780818469266\n",
      "\n",
      "--- entry_rate_pct ---\n",
      "0.20160246504119123\n",
      "\n",
      "--- trade_count ---\n",
      "1156\n",
      "\n",
      "--- win_rate ---\n",
      "0.27854671280276816\n",
      "\n",
      "--- avg_pnl ---\n",
      "0.22513745480994052\n",
      "\n",
      "--- max_loss_cap ---\n",
      "-3.0\n",
      "\n",
      "--- decay_factor ---\n",
      "0.1\n",
      "\n",
      "--- side_mode ---\n",
      "both\n",
      "\n",
      "--- hold_distribution ---\n",
      "count    578.000000\n",
      "mean      39.192042\n",
      "std       13.617814\n",
      "min        2.000000\n",
      "25%       29.000000\n",
      "50%       48.000000\n",
      "75%       50.000000\n",
      "max       50.000000\n",
      "Name: hold, dtype: float64\n",
      "\n",
      "--- exit_reason_counts ---\n",
      "reason\n",
      "NaN           578\n",
      "TIME          277\n",
      "DECAY         200\n",
      "HARD_STOP      56\n",
      "MODEL_FLIP     45\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- top_5_winners ---\n",
      "     type  signal      price   index  pred_ret_entry       pnl  hold reason\n",
      "961  EXIT     NaN  108500.00  554853             NaN  7.966974  50.0   TIME\n",
      "531  EXIT     NaN   53411.91  313355             NaN  6.918825  50.0   TIME\n",
      "133  EXIT     NaN   61538.01   84596             NaN  6.587762  25.0  DECAY\n",
      "303  EXIT     NaN   65187.74  149721             NaN  6.481311  50.0   TIME\n",
      "833  EXIT     NaN  103077.27  488363             NaN  6.249596  50.0   TIME\n",
      "\n",
      "--- top_5_losers ---\n",
      "     type  signal     price   index  pred_ret_entry       pnl  hold     reason\n",
      "841  EXIT     NaN  92656.41  489508             NaN -9.346327   2.0  HARD_STOP\n",
      "59   EXIT     NaN  41750.07   17181             NaN -5.408879  18.0  HARD_STOP\n",
      "285  EXIT     NaN  66518.72  132639             NaN -4.972945   5.0  HARD_STOP\n",
      "155  EXIT     NaN  62404.92   90769             NaN -4.963190  11.0  HARD_STOP\n",
      "183  EXIT     NaN  68011.03   97412             NaN -4.251863   4.0  HARD_STOP\n",
      "\n",
      "--- pred_ret_pnl_corr ---\n",
      "0.6396661285142576\n"
     ]
    }
   ],
   "source": [
    "results = backtest_regression_simple_centered_v4(\n",
    "    df=df,\n",
    "    y_pred=y_pred_unscaled,\n",
    "    config=config,\n",
    "    horizon=50,\n",
    "    quantile=0.98,\n",
    "    max_hold=50,\n",
    "    invert_signal=True,\n",
    "    side_mode=\"both\",   # try \"both\", \"long_only\", \"short_only\"\n",
    "    max_loss_cap=-3.0,\n",
    "    decay_factor=0.1,\n",
    ")\n",
    "\n",
    "print(\"\\n--- Backtest Results ---\")\n",
    "print(f\"Final Balance: {results['final_balance']:.2f}\")\n",
    "print(f\"Profit %: {results['profit_pct']:.2f}%\")\n",
    "print(f\"Trades: {len(results['trades'])}\")\n",
    "print(f\"Win Rate: {results['diagnostics']['win_rate']:.2%}\")\n",
    "print(f\"Avg PnL: {results['diagnostics']['avg_pnl']:.6f}\")\n",
    "print(f\"Max DD: {results['max_drawdown']:.2%}\")\n",
    "\n",
    "print(\"\\n=== DIAGNOSTICS ===\")\n",
    "for k, v in results[\"diagnostics\"].items():\n",
    "    print(f\"\\n--- {k} ---\\n{v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8431d82f-6dd2-4d6b-9cf5-3e8f49b88f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m135",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m135"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
