{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5452838e-7026-4ea1-8fb7-b590ee4e16a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f73f0b22-fdcf-4366-a303-6b133e37fe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6246e201-ca3e-424c-9635-beb01679291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_cnn(df, window_size):\n",
    "    data = df.values\n",
    "    num_samples = (len(data) - window_size) // window_size\n",
    "    reshaped_data = []\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        start = i * window_size\n",
    "        end = start + window_size\n",
    "        reshaped_data.append(data[start:end])\n",
    "\n",
    "    reshaped_data = np.array(reshaped_data)\n",
    "    reshaped_data = reshaped_data.reshape(\n",
    "        (reshaped_data.shape[0], window_size, data.shape[1], 1))  # Add channel dimension\n",
    "\n",
    "    return reshaped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bf022574-97c3-4d5d-a009-e94be92c5513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_labels(df, window_size):\n",
    "    # Shift 'Close' prices to create labels\n",
    "    y_labels = df['Close'].shift(-1).values\n",
    "\n",
    "    # Remove the last `window_size` labels which will be NaN after shifting\n",
    "    y_labels = y_labels[:-window_size]\n",
    "\n",
    "    # Remove the first `window_size` entries from 'Close' to align with labels\n",
    "    close_prices = df['Close'].values[window_size:]\n",
    "\n",
    "    # Create binary labels: 1 if the next price is higher, else 0\n",
    "    y_labels = np.where(y_labels > close_prices, 1, 0).astype(np.float32)\n",
    "\n",
    "    return y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "51cd6e60-8f04-4274-b788-19f491e0cb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_functional_model(input_shape, num_filters, kernel_size, pool_size, dropout_rate, activation, output_activation, num_classes):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # First Convolutional Block\n",
    "    x = Conv2D(num_filters[0], kernel_size, activation=activation, padding='same')(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=pool_size)(x)\n",
    "\n",
    "    # Second Convolutional Block\n",
    "    x = Conv2D(num_filters[1], kernel_size, activation=activation, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=pool_size)(x)\n",
    "\n",
    "    # Third Convolutional Block\n",
    "    x = Conv2D(num_filters[2], kernel_size, activation=activation, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=pool_size)(x)\n",
    "\n",
    "    # Additional Convolutional Block\n",
    "    x = Conv2D(256, kernel_size, activation=activation, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=pool_size)(x)\n",
    "\n",
    "    # Flatten and Dense layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation=activation, kernel_regularizer='l2')(x)  # L2 regularization\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Dense(128, activation=activation, kernel_regularizer='l2')(x)\n",
    "\n",
    "    # Output layer\n",
    "    output_layer = Dense(num_classes, activation=output_activation)(x)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    return model  # Ensure that the model is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "57e9e09b-3e7c-4ebd-a7fb-34202ffce6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2380/2380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 52ms/step - binary_accuracy: 0.5356 - loss: 1.6341 - val_binary_accuracy: 0.5435 - val_loss: 0.6905\n",
      "Epoch 2/10\n",
      "\u001b[1m2380/2380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 55ms/step - binary_accuracy: 0.5407 - loss: 0.6906 - val_binary_accuracy: 0.5435 - val_loss: 0.6897\n",
      "Epoch 3/10\n",
      "\u001b[1m2380/2380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 51ms/step - binary_accuracy: 0.5319 - loss: 0.6913 - val_binary_accuracy: 0.5435 - val_loss: 0.6895\n",
      "Epoch 4/10\n",
      "\u001b[1m2380/2380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 47ms/step - binary_accuracy: 0.5383 - loss: 0.6905 - val_binary_accuracy: 0.5435 - val_loss: 0.6896\n",
      "Epoch 5/10\n",
      "\u001b[1m2380/2380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 47ms/step - binary_accuracy: 0.5337 - loss: 0.6910 - val_binary_accuracy: 0.5435 - val_loss: 0.6898\n",
      "Epoch 6/10\n",
      "\u001b[1m2380/2380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 46ms/step - binary_accuracy: 0.5336 - loss: 0.6912 - val_binary_accuracy: 0.5435 - val_loss: 0.6896\n",
      "Epoch 7/10\n",
      "\u001b[1m2380/2380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 46ms/step - binary_accuracy: 0.5433 - loss: 0.6896 - val_binary_accuracy: 0.5435 - val_loss: 0.6902\n",
      "Epoch 8/10\n",
      "\u001b[1m2380/2380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 50ms/step - binary_accuracy: 0.5314 - loss: 0.6914 - val_binary_accuracy: 0.5435 - val_loss: 0.6894\n",
      "Epoch 9/10\n",
      "\u001b[1m2380/2380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 48ms/step - binary_accuracy: 0.5357 - loss: 0.6910 - val_binary_accuracy: 0.5435 - val_loss: 0.6894\n",
      "Epoch 10/10\n",
      "\u001b[1m2380/2380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 48ms/step - binary_accuracy: 0.5377 - loss: 0.6905 - val_binary_accuracy: 0.5435 - val_loss: 0.6895\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - binary_accuracy: 0.5483 - loss: 0.6889\n",
      "Test loss: 0.6879483461380005\n",
      "Test accuracy: 0.5551075339317322\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Load configuration\n",
    "    config = load_config(r\"C:\\Users\\Arun2\\Documents\\Project\\Trading Strat\\Config\\config.yaml\")\n",
    "\n",
    "    # Load preprocessed data\n",
    "    df = pd.read_csv(config['data']['data_path'])\n",
    "\n",
    "    # Prepare data for CNN\n",
    "    window_size = config['data']['sequence_length']\n",
    "    cnn_data = prepare_data_for_cnn(df, window_size)\n",
    "\n",
    "    # Prepare labels\n",
    "    y_labels = prepare_labels(df, window_size)\n",
    "\n",
    "    # Adjust labels to match data length\n",
    "    y_labels = y_labels[:cnn_data.shape[0]]\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    validation_split = config['data']['validation_split']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(cnn_data, y_labels, test_size=validation_split,\n",
    "                                                        random_state=config['misc']['random_seed'])\n",
    "\n",
    "    # Build the CNN model\n",
    "    input_shape = (window_size, cnn_data.shape[2], 1)  # (time steps, features, channels)\n",
    "    num_classes = 1  # Binary classification\n",
    "    model = build_functional_model(\n",
    "        input_shape=input_shape,\n",
    "        num_filters=config['keras']['model']['cnn']['num_filters'],\n",
    "        kernel_size=tuple(config['keras']['model']['cnn']['kernel_size']),\n",
    "        pool_size=tuple(config['keras']['model']['cnn']['pool_size']),\n",
    "        dropout_rate=config['keras']['model']['cnn']['dropout_rate'],\n",
    "        activation=config['keras']['model']['cnn']['activation'],\n",
    "        output_activation='sigmoid',  # Sigmoid for binary classification\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "\n",
    "    # Compile the model with the optimizer, loss function, and metrics from config\n",
    "    optimizer = Adam(learning_rate=config['keras']['training']['learning_rate'])\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=[BinaryAccuracy()])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=30,\n",
    "              batch_size=config['keras']['training']['batch_size'], validation_split=validation_split)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0f0e9043-3cd4-4bac-a5fe-a0db27cfd2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Translate model outputs into signals\n",
    "buy_threshold = 0.6   # Set threshold for a strong buy\n",
    "sell_threshold = 0.4  # Set threshold for a strong sell\n",
    "\n",
    "buy_signals = predictions > buy_threshold\n",
    "sell_signals = predictions < sell_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a874676e-6157-4f8e-8742-5b939fc7e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_balance = 10000  # Starting with $10,000\n",
    "balance = initial_balance\n",
    "positions = 0  # Tracks how many units are held\n",
    "trade_log = []  # Log to store trade details\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    price = df['Close'].iloc[i + len(X_train)]  # Get the current close price\n",
    "\n",
    "    # Buy signal\n",
    "    if buy_signals[i]:\n",
    "        units = balance // price  # Buy as many units as possible\n",
    "        balance -= units * price\n",
    "        positions += units\n",
    "        trade_log.append(f\"Buy at {price}, Units: {units}\")\n",
    "\n",
    "    # Sell signal\n",
    "    elif sell_signals[i] and positions > 0:\n",
    "        balance += positions * price  # Sell all units\n",
    "        trade_log.append(f\"Sell at {price}, Profit: {positions * price}\")\n",
    "        positions = 0\n",
    "\n",
    "# Final balance and positions after backtest\n",
    "if positions > 0:\n",
    "    final_value = balance + positions * df['Close'].iloc[-1]\n",
    "else:\n",
    "    final_value = balance\n",
    "profit = final_value - initial_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ccfd11a3-2651-4d31-8abc-957c0f32f9df",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[130], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m total_trades \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(trade_log)\n\u001b[0;32m      2\u001b[0m successful_trades \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m trade \u001b[38;5;129;01min\u001b[39;00m trade_log \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProfit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m trade])\n\u001b[1;32m----> 3\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43msuccessful_trades\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtotal_trades\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "total_trades = len(trade_log)\n",
    "successful_trades = sum([1 for trade in trade_log if \"Profit\" in trade])\n",
    "accuracy = successful_trades / total_trades * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e73c762-ee23-4c11-9a87-0bf3b78b31ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conntrading",
   "language": "python",
   "name": "conntrading"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
